{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- 1. [Analyse de Sentiment Basée sur des Tweets - Modèle Baseline](#toc1_)    \n",
    "  - 1.1. [Préparation des Données](#toc1_1_)    \n",
    "  - 1.2. [Vectorisation des Tweets](#toc1_2_)    \n",
    "  - 1.3. [Entraînement et Évaluation du Modèle](#toc1_3_)    \n",
    "  - 1.4. [Comparaison des Résultats](#toc1_4_)    \n",
    "    - 1.4.1. [Comparaison des Performances entre TF-IDF et Count Vectorizer](#toc1_4_1_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=true\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. <a id='toc1_'></a>[Analyse de Sentiment Basée sur des Tweets - Modèle Baseline](#toc0_)\n",
    "\n",
    "Ce notebook présente un modèle de base pour l'analyse de sentiment de tweets en utilisant la **régression logistique**. Nous explorerons deux méthodes de vectorisation du texte : **TF-IDF** et **Count Vectorizer**, afin de convertir le texte en caractéristiques numériques exploitables par le modèle. \n",
    "\n",
    "Les principaux objectifs sont :\n",
    "- Préparer les données textuelles en utilisant des méthodes de vectorisation.\n",
    "- Entraîner un modèle de régression logistique sur les tweets vectorisés.\n",
    "- Suivre et évaluer les performances du modèle en utilisant **MLFlow** pour chaque méthode de vectorisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manipulation de données et calculs\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Bibliothèques pour la vectorisation et la transformation des textes\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "# Modèle de régression logistique pour la classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Bibliothèques pour la division des données et les métriques d'évaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score\n",
    "\n",
    "# Bibliothèque pour le suivi des expérimentations\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.models.signature import infer_signature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. <a id='toc1_1_'></a>[Préparation des Données](#toc0_)\n",
    "\n",
    "Nous chargeons le dataset prétraité, qui contient les tweets et leur sentiment associé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les données prétraitées\n",
    "df = pd.read_csv('../data/processed_tweets.csv')\n",
    "X_text = df['text']\n",
    "y = df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>awww thats bummer shoulda got david carr third...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>upset cant update facebook texting might cry r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>dived many time ball managed save 50 rest go b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>whole body feel itchy like fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>behaving im mad cant see</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                               text\n",
       "0          0  awww thats bummer shoulda got david carr third...\n",
       "1          0  upset cant update facebook texting might cry r...\n",
       "2          0  dived many time ball managed save 50 rest go b...\n",
       "3          0                    whole body feel itchy like fire\n",
       "4          0                           behaving im mad cant see"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///e:/Openclassroom/AI_Engineer/Projet_07/work_folder/mlruns/904868608763176366', creation_time=1732026600769, experiment_id='904868608763176366', last_update_time=1732026600769, lifecycle_stage='active', name='Sentiment_Analysis_Baseline_Model', tags={}>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialiser MLFlow et Démarrer une Expérimentation\n",
    "mlflow.set_experiment(\"Sentiment_Analysis_Baseline_Model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. <a id='toc1_2_'></a>[Vectorisation des Tweets](#toc0_)\n",
    "\n",
    "Nous utilisons **TF-IDF** et **Count Vectorizer** pour créer des représentations numériques des tweets. TF-IDF pèse l’importance des mots en fonction de leur fréquence, tandis que Count Vectorizer compte les occurrences de chaque mot. Nous limiterons les caractéristiques à un maximum de 5000 mots pour optimiser le modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer les Features avec TF-IDF et Count Vectorizer\n",
    "vectorizer_tfidf = TfidfVectorizer(max_features=5000)\n",
    "vectorizer_count = CountVectorizer(max_features=5000)\n",
    "\n",
    "# Vectoriser les textes en utilisant TF-IDF\n",
    "X_tfidf = vectorizer_tfidf.fit_transform(X_text)\n",
    "# Vectoriser les textes en utilisant Count Vectorizer\n",
    "X_count = vectorizer_count.fit_transform(X_text)\n",
    "\n",
    "# Diviser les données en jeu d'entraînement et de test pour chaque méthode\n",
    "X_train_tfidf, X_test_tfidf, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n",
    "X_train_count, X_test_count, _, _ = train_test_split(X_count, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. <a id='toc1_3_'></a>[Entraînement et Évaluation du Modèle](#toc0_)\n",
    "\n",
    "Dans cette section, nous entraînons un modèle de **régression logistique** pour chaque méthode de vectorisation. Nous utilisons MLFlow pour suivre les expérimentations et enregistrer les métriques clés, telles que la précision, le F1-score et le ROC-AUC, afin de comparer les performances des deux méthodes de vectorisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c7f0849f1194db6b540481e12db6ed7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle enregistré sous : ../saved_models\\logistic_regression_tf-idf.pkl\n",
      "Vectorizer enregistré sous : ../saved_models\\tf-idf_vectorizer.pkl\n",
      "Modèle enregistré dans MLFlow sous le chemin : baseline_model_tf-idf\n",
      "Results for TF-IDF:\n",
      "Accuracy: 0.7750, ROC-AUC: 0.8551, Training Time: 2.62 seconds\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.76      0.77    158794\n",
      "           1       0.77      0.79      0.78    159876\n",
      "\n",
      "    accuracy                           0.78    318670\n",
      "   macro avg       0.78      0.77      0.77    318670\n",
      "weighted avg       0.78      0.78      0.77    318670\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9aa2469ec8a2447797d758aa02d9c77c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle enregistré sous : ../saved_models\\logistic_regression_count_vectorizer.pkl\n",
      "Vectorizer enregistré sous : ../saved_models\\count_vectorizer_vectorizer.pkl\n",
      "Modèle enregistré dans MLFlow sous le chemin : baseline_model_count_vectorizer\n",
      "Results for Count Vectorizer:\n",
      "Accuracy: 0.7747, ROC-AUC: 0.8492, Training Time: 4.20 seconds\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.74      0.77    158794\n",
      "           1       0.76      0.81      0.78    159876\n",
      "\n",
      "    accuracy                           0.77    318670\n",
      "   macro avg       0.78      0.77      0.77    318670\n",
      "weighted avg       0.78      0.77      0.77    318670\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Créer un dossier pour sauvegarder les modèles\n",
    "output_dir = \"../saved_models\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Nommer l'expérience dans MLFlow\n",
    "mlflow.set_experiment(\"Sentiment_Analysis_Baseline_Model\")\n",
    "\n",
    "# Entraîner les modèles et suivre les expérimentations\n",
    "for vectorizer_name, X_train, X_test in [(\"TF-IDF\", X_train_tfidf, X_test_tfidf), (\"Count Vectorizer\", X_train_count, X_test_count)]:\n",
    "    with mlflow.start_run():\n",
    "        # Mesurer le temps d’entraînement\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Entraîner le modèle\n",
    "        model = LogisticRegression()\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Calculer le temps écoulé\n",
    "        elapsed_time = time.time() - start_time\n",
    "\n",
    "        # Prédictions et Probabilités\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        # Évaluation des performances\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        report = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "        # Loguer les paramètres et métriques dans MLFlow\n",
    "        mlflow.log_param(\"vectorizer\", vectorizer_name)\n",
    "        mlflow.log_param(\"model_type\", \"Logistic Regression\")\n",
    "        mlflow.log_param(\"max_features\", 5000)\n",
    "\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        mlflow.log_metric(\"roc_auc\", roc_auc)\n",
    "        mlflow.log_metric(\"precision\", report[\"weighted avg\"][\"precision\"])\n",
    "        mlflow.log_metric(\"recall\", report[\"weighted avg\"][\"recall\"])\n",
    "        mlflow.log_metric(\"f1-score\", report[\"weighted avg\"][\"f1-score\"])\n",
    "        mlflow.log_metric(\"training_time_seconds\", elapsed_time)\n",
    "\n",
    "        # Exemple d'entrée pour MLFlow\n",
    "        input_example = X_test[0].toarray()  # Convertir le premier tweet vectorisé en format array\n",
    "\n",
    "        # Signature du modèle\n",
    "        signature = infer_signature(X_test, model.predict(X_test))\n",
    "\n",
    "        # Enregistrer le modèle avec signature et exemple dans MLFlow\n",
    "        mlflow.sklearn.log_model(\n",
    "            sk_model=model,\n",
    "            artifact_path=f\"baseline_model_{vectorizer_name.lower().replace(' ', '_')}\",\n",
    "            input_example=input_example,\n",
    "            signature=signature\n",
    "        )\n",
    "\n",
    "        # Enregistrer le modèle et le vectorizer dans des fichiers locaux\n",
    "        model_file = os.path.join(output_dir, f\"logistic_regression_{vectorizer_name.lower().replace(' ', '_')}.pkl\")\n",
    "        vectorizer_file = os.path.join(output_dir, f\"{vectorizer_name.lower().replace(' ', '_')}_vectorizer.pkl\")\n",
    "\n",
    "        joblib.dump(model, model_file)\n",
    "        joblib.dump(vectorizer_tfidf if vectorizer_name == \"TF-IDF\" else vectorizer_count, vectorizer_file)\n",
    "\n",
    "        # Afficher les informations\n",
    "        print(f\"Modèle enregistré sous : {model_file}\")\n",
    "        print(f\"Vectorizer enregistré sous : {vectorizer_file}\")\n",
    "        print(f\"Modèle enregistré dans MLFlow sous le chemin : baseline_model_{vectorizer_name.lower().replace(' ', '_')}\")\n",
    "        print(f\"Results for {vectorizer_name}:\")\n",
    "        print(f\"Accuracy: {accuracy:.4f}, ROC-AUC: {roc_auc:.4f}, Training Time: {elapsed_time:.2f} seconds\")\n",
    "        print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projet_7_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
