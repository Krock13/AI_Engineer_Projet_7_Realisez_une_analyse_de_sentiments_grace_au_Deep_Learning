{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- 1. [**Analyse de Sentiment avec BERT**](#toc1_)    \n",
    "  - 1.1. [**Objectifs**](#toc1_1_)    \n",
    "  - 1.2. [**Méthodologie**](#toc1_2_)    \n",
    "  - 1.3. [**Pourquoi BERT ?**](#toc1_3_)    \n",
    "  - 1.4. [**Échantillonnage des Données**](#toc1_4_)    \n",
    "  - 1.5. [**Préparation des Données pour BERT**](#toc1_5_)    \n",
    "  - 1.6. [**Configuration et Préparation du Modèle BERT**](#toc1_6_)    \n",
    "  - 1.7. [**Entraînement du Modèle BERT avec Suivi via MLFlow**](#toc1_7_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=true\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. <a id='toc1_'></a>[**Analyse de Sentiment avec BERT**](#toc0_)\n",
    "\n",
    "Ce notebook explore l'utilisation du modèle **BERT** (Bidirectional Encoder Representations from Transformers) pour l'analyse de sentiment sur des tweets. L'objectif est de fine-tuner BERT pour prédire si un tweet exprime un sentiment positif ou négatif.\n",
    "\n",
    "## 1.1. <a id='toc1_1_'></a>[**Objectifs**](#toc0_)\n",
    "- Adapter (fine-tune) le modèle BERT sur un dataset de tweets annotés pour la classification binaire des sentiments.\n",
    "- Évaluer les performances à l'aide de métriques comme l'accuracy, la loss et le ROC-AUC.\n",
    "- Suivre et documenter les expérimentations avec **MLFlow**, en incluant les hyperparamètres, les métriques et le modèle final.\n",
    "\n",
    "## 1.2. <a id='toc1_2_'></a>[**Méthodologie**](#toc0_)\n",
    "1. **Prétraitement des données** : Nettoyage et tokenisation des tweets pour BERT.\n",
    "2. **Fine-tuning de BERT** : Utilisation de `TFBertForSequenceClassification` pour entraîner le modèle.\n",
    "3. **Évaluation des performances** : Calcul des métriques sur les données de validation et de test.\n",
    "4. **Enregistrement des résultats avec MLFlow** : Hyperparamètres, métriques et modèle final.\n",
    "\n",
    "## 1.3. <a id='toc1_3_'></a>[**Pourquoi BERT ?**](#toc0_)\n",
    "BERT est un modèle pré-entraîné puissant pour comprendre les relations contextuelles entre les mots. Cela en fait un choix idéal pour une tâche comme l'analyse de sentiment, où la compréhension du contexte est essentielle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From e:\\Openclassroom\\AI_Engineer\\Projet_07\\work_folder\\projet_7_env\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Manipulation de données et calculs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "\n",
    "# Outils pour la gestion des ensembles de données et l'évaluation des modèles\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Bibliothèques pour la construction et l'entraînement des modèles\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "from transformers import create_optimizer\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "# Suivi et enregistrement des expérimentations avec MLFlow\n",
    "import mlflow\n",
    "import mlflow.keras\n",
    "from mlflow.models.signature import infer_signature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. <a id='toc1_4_'></a>[**Échantillonnage des Données**](#toc0_)\n",
    "\n",
    "En raison des ressources limitées pour l'entraînement, nous travaillons sur un sous-ensemble équilibré du dataset complet. Nous sélectionnons un échantillon de **200 000 tweets par classe** (positif et négatif), soit un total de **400 000 tweets**, tout en maintenant une distribution équilibrée des sentiments.\n",
    "\n",
    "Cela permet de réduire le temps d'entraînement et les besoins en mémoire tout en conservant une représentativité suffisante des données pour fine-tuner BERT efficacement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment\n",
      "1    200000\n",
      "0    200000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Charger les données\n",
    "data_path = '../data/training.1600000.processed.noemoticon.csv'\n",
    "df = pd.read_csv(data_path, encoding='ISO-8859-1', header=None)\n",
    "\n",
    "df.columns = ['sentiment', 'id', 'date', 'query', 'user', 'text']\n",
    "\n",
    "# Mapper les sentiments à des valeurs binaires\n",
    "df['sentiment'] = df['sentiment'].map({0: 0, 4: 1})\n",
    "\n",
    "# Garder uniquement les colonnes utiles\n",
    "df = df[['sentiment', 'text']]\n",
    "\n",
    "# Échantillonnage équilibré\n",
    "sample_size = 200_000  # Nombre de tweets par classe\n",
    "df_positive = df[df['sentiment'] == 1].sample(n=sample_size, random_state=42)\n",
    "df_negative = df[df['sentiment'] == 0].sample(n=sample_size, random_state=42)\n",
    "\n",
    "# Combiner les deux échantillons\n",
    "df_sampled = pd.concat([df_positive, df_negative]).sample(frac=1, random_state=42)  # Mélanger les tweets\n",
    "\n",
    "# Vérifier la répartition\n",
    "print(df_sampled['sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appliquer un nettoyage simple\n",
    "def preprocess_tweet_for_sentiment(text):\n",
    "    # Supprimer les mentions @pseudo\n",
    "    text = re.sub(r'@\\w+', '', text)\n",
    "    # Supprimer les espaces superflus\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "df_sampled['text'] = df_sampled['text'].apply(preprocess_tweet_for_sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5. <a id='toc1_5_'></a>[**Préparation des Données pour BERT**](#toc0_)\n",
    "\n",
    "Dans ce bloc, nous préparons les données échantillonnées pour l'entraînement avec BERT. Les étapes principales incluent :\n",
    "\n",
    "1. **Chargement du Tokenizer BERT** :\n",
    "   Nous utilisons le tokenizer pré-entraîné de BERT pour convertir les tweets en une séquence de tokens que le modèle peut comprendre.\n",
    "\n",
    "2. **Tokenisation des Tweets** :\n",
    "   - Chaque tweet est converti en tokens avec un remplissage (`padding`) pour garantir que toutes les séquences ont la même longueur.\n",
    "   - Les séquences sont tronquées (`truncation`) à une longueur maximale de 100 tokens.\n",
    "   - Les résultats sont renvoyés sous forme de tenseurs pour faciliter leur utilisation dans TensorFlow.\n",
    "\n",
    "3. **Préparation des Labels** :\n",
    "   - Les labels (`sentiment`) sont convertis en tenseurs TensorFlow.\n",
    "\n",
    "4. **Division des Données** :\n",
    "   - Les données tokenisées sont divisées en jeux d'entraînement (80%) et de test (20%).\n",
    "   - Cela s'applique aux tokens et aux labels, garantissant que chaque ensemble correspond.\n",
    "\n",
    "5. **Vérification des Dimensions** :\n",
    "   - Nous affichons les dimensions des jeux d'entraînement et de test pour valider leur cohérence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (320000, 100), X_test: (80000, 100)\n",
      "y_train: (320000,), y_test: (80000,)\n"
     ]
    }
   ],
   "source": [
    "# Charger le tokenizer Bert\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokenizer les tweets échantillonnés\n",
    "X_tokenized = tokenizer(\n",
    "    list(df_sampled['text']),  # Utiliser les données échantillonnées\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=100,\n",
    "    return_tensors=\"tf\"\n",
    ")\n",
    "\n",
    "# Préparer les labels\n",
    "y = tf.convert_to_tensor(df_sampled['sentiment'].values)\n",
    "\n",
    "# Diviser en jeu d'entraînement et de test\n",
    "X_train = {\n",
    "    key: value[:int(0.8 * len(value))] for key, value in X_tokenized.items()\n",
    "}\n",
    "X_test = {\n",
    "    key: value[int(0.8 * len(value)):] for key, value in X_tokenized.items()\n",
    "}\n",
    "y_train = y[:int(0.8 * len(y))]\n",
    "y_test = y[int(0.8 * len(y)):]\n",
    "\n",
    "# Vérifier les dimensions\n",
    "print(f\"X_train: {X_train['input_ids'].shape}, X_test: {X_test['input_ids'].shape}\")\n",
    "print(f\"y_train: {y_train.shape}, y_test: {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6. <a id='toc1_6_'></a>[**Configuration et Préparation du Modèle BERT**](#toc0_)\n",
    "\n",
    "Nous configurons ensuite et préparons le modèle BERT pour la classification binaire des sentiments. Les étapes principales incluent :\n",
    "\n",
    "1. **Chargement du Modèle Pré-entraîné BERT** :\n",
    "   - Nous utilisons `TFBertForSequenceClassification` avec deux labels (`num_labels=2`) pour une tâche de classification binaire.\n",
    "\n",
    "2. **Définition de l'Optimiseur et de la Fonction de Perte** :\n",
    "   - **Optimiseur** : `Adam` est utilisé avec un taux d'apprentissage initial de `2e-5`, adapté à l'entraînement de modèles pré-entraînés.\n",
    "   - **Fonction de Perte** : `SparseCategoricalCrossentropy` est utilisée pour les données avec labels entiers (`0` ou `1`) et des sorties du modèle sous forme de logits.\n",
    "\n",
    "3. **Calcul des Étapes d'Entraînement** :\n",
    "   - **Batch Size** : Défini à 32 pour contrôler le nombre d'exemples traités par étape.\n",
    "   - **Épochs** : Nombre d'épochs fixé à 3 pour un entraînement rapide et efficace.\n",
    "   - **Étapes par Époch** : Calculé comme la taille des données d'entraînement divisée par la taille du batch.\n",
    "   - **Étapes Totales** : Produit du nombre d'épochs et d'étapes par époch.\n",
    "   - **Warm-up Steps** : Défini à 10% des étapes totales pour une montée progressive du taux d'apprentissage, réduisant le risque de divergence au début de l'entraînement.\n",
    "\n",
    "4. **Création d’un Optimiseur Avancé** :\n",
    "   - Nous utilisons une fonction personnalisée `create_optimizer` pour intégrer un planning d'apprentissage dynamique (`schedule`), permettant de réduire progressivement le taux d'apprentissage après les étapes de warm-up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From e:\\Openclassroom\\AI_Engineer\\Projet_07\\work_folder\\projet_7_env\\lib\\site-packages\\tf_keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Charger le modèle Bert pour la classification\n",
    "model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "\n",
    "# Définir l'optimiseur et la fonction de perte\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5)\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul des étapes totales et warm-up steps\n",
    "batch_size = 32\n",
    "epochs = 3\n",
    "steps_per_epoch = len(y_train) // batch_size\n",
    "total_training_steps = steps_per_epoch * epochs\n",
    "warmup_steps = int(0.1 * total_training_steps)\n",
    "\n",
    "# Créer un optimiseur compatible avec Transformers\n",
    "optimizer, schedule = create_optimizer(\n",
    "    init_lr=2e-5,  # Taux d'apprentissage initial\n",
    "    num_train_steps=total_training_steps,  # Étapes totales d'entraînement\n",
    "    num_warmup_steps=warmup_steps,  # Étapes de warm-up\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7. <a id='toc1_7_'></a>[**Entraînement du Modèle BERT avec Suivi via MLFlow**](#toc0_)\n",
    "\n",
    "Dans ce bloc, nous effectuons l’entraînement du modèle BERT tout en utilisant MLFlow pour suivre et enregistrer les paramètres, métriques et le modèle final.\n",
    "\n",
    "1. **Définition de l'Expérience MLFlow** :\n",
    "   - L'expérience `Sentiment_Analysis_BERT_Model` est définie pour centraliser les enregistrements liés à cet entraînement.\n",
    "\n",
    "2. **Compilation et Entraînement du Modèle** :\n",
    "   - **Compilation** : Le modèle est compilé avec l’optimiseur et la fonction de perte définis précédemment, et nous suivons l'accuracy comme métrique.\n",
    "   - **Entraînement** : Le modèle est entraîné sur les données d’entraînement (`X_train` et `y_train`) avec une division interne de validation (`validation_split=0.2`) pour évaluer les performances à chaque époque. \n",
    "\n",
    "3. **Évaluation des Performances** :\n",
    "   - **Validation Accuracy** et **Loss** : Obtenus à partir de l’historique d’entraînement.\n",
    "   - **ROC-AUC** : Calculé à l’aide des prédictions (`y_pred`) sur le jeu de test (`X_test`), pour une meilleure évaluation de la capacité du modèle à différencier les classes.\n",
    "\n",
    "4. **Suivi des Performances avec MLFlow** :\n",
    "   - Les paramètres (modèle, taille des batchs, nombre d’épochs) et les métriques (accuracy, perte, ROC-AUC, temps d’entraînement) sont enregistrés dans MLFlow pour permettre une analyse comparative.\n",
    "\n",
    "5. **Préparation de la Signature pour le Modèle** :\n",
    "   - Les données de test (`X_test`) sont combinées pour correspondre au format attendu par MLFlow pour définir une **signature**. Celle-ci permet de documenter les types d'entrée et de sortie pour un éventuel déploiement.\n",
    "\n",
    "6. **Enregistrement du Modèle** :\n",
    "   - Le modèle est enregistré avec la signature et les dépendances requises spécifiées dans `requirements.txt`. Cela facilite la réutilisation ou le déploiement du modèle à l'avenir.\n",
    "\n",
    "**Résultat** :\n",
    "Le modèle est entraîné et évalué, ses performances sont enregistrées, et il est sauvegardé dans un format exploitable pour de futures itérations ou intégrations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "WARNING:tensorflow:From e:\\Openclassroom\\AI_Engineer\\Projet_07\\work_folder\\projet_7_env\\lib\\site-packages\\tf_keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From e:\\Openclassroom\\AI_Engineer\\Projet_07\\work_folder\\projet_7_env\\lib\\site-packages\\tf_keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "8000/8000 [==============================] - 19535s 2s/step - loss: 0.3839 - accuracy: 0.8257 - val_loss: 0.3412 - val_accuracy: 0.8547\n",
      "Epoch 2/3\n",
      "8000/8000 [==============================] - 19275s 2s/step - loss: 0.2834 - accuracy: 0.8812 - val_loss: 0.3437 - val_accuracy: 0.8579\n",
      "Epoch 3/3\n",
      "8000/8000 [==============================] - 19847s 2s/step - loss: 0.1948 - accuracy: 0.9234 - val_loss: 0.3948 - val_accuracy: 0.8563\n",
      "2500/2500 [==============================] - 1705s 682ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Openclassroom\\AI_Engineer\\Projet_07\\work_folder\\projet_7_env\\lib\\site-packages\\transformers\\generation\\tf_utils.py:465: UserWarning: `seed_generator` is deprecated and will be removed in a future version.\n",
      "  warnings.warn(\"`seed_generator` is deprecated and will be removed in a future version.\", UserWarning)\n",
      "2024/12/10 16:45:51 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: C:\\Users\\black\\AppData\\Local\\Temp\\tmpfff2yu65\\model, flavor: keras). Fall back to return ['keras==3.6.0']. Set logging level to DEBUG to see the full traceback. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT - Validation Accuracy: 0.8563, Loss: 0.3948, ROC-AUC: 0.9333, Training Time: 58656.99s\n"
     ]
    }
   ],
   "source": [
    "# Définir l'expérience MLFlow\n",
    "mlflow.set_experiment(\"Sentiment_Analysis_BERT_Model\")\n",
    "\n",
    "# Entraîner BERT\n",
    "with mlflow.start_run():\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Compiler le modèle avec l'optimiseur compatible\n",
    "    model.compile(optimizer=optimizer, loss=loss_fn, metrics=['accuracy'])\n",
    "\n",
    "    # Entraîner le modèle\n",
    "    history = model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        validation_split=0.2,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    # Évaluer les performances\n",
    "    val_accuracy = history.history['val_accuracy'][-1]\n",
    "    val_loss = history.history['val_loss'][-1]\n",
    "    y_pred = model.predict(X_test).logits\n",
    "    roc_auc = roc_auc_score(y_test.numpy(), tf.nn.softmax(y_pred)[:, 1].numpy())\n",
    "\n",
    "    # Logger les paramètres et métriques dans MLFlow\n",
    "    mlflow.log_param(\"model\", \"BERT\")\n",
    "    mlflow.log_param(\"batch_size\", batch_size)\n",
    "    mlflow.log_param(\"epochs\", epochs)\n",
    "    mlflow.log_metric(\"val_accuracy\", val_accuracy)\n",
    "    mlflow.log_metric(\"val_loss\", val_loss)\n",
    "    mlflow.log_metric(\"roc_auc\", roc_auc)\n",
    "    mlflow.log_metric(\"training_time_seconds\", elapsed_time)\n",
    "\n",
    "    # Préparer les données de test pour la signature\n",
    "    X_test_combined = np.hstack([\n",
    "        X_test[\"input_ids\"].numpy(),\n",
    "        X_test[\"attention_mask\"].numpy(),\n",
    "        X_test[\"token_type_ids\"].numpy(),\n",
    "    ])\n",
    "\n",
    "    # Définir une signature pour le modèle\n",
    "    signature = infer_signature(X_test_combined, y_pred)\n",
    "\n",
    "    # Enregistrer le modèle avec signature dans MLFlow\n",
    "    mlflow.keras.log_model(\n",
    "        model=model,\n",
    "        artifact_path=\"bert_model\",\n",
    "        signature=signature,\n",
    "    )\n",
    "\n",
    "    print(f\"BERT - Validation Accuracy: {val_accuracy:.4f}, Loss: {val_loss:.4f}, ROC-AUC: {roc_auc:.4f}, Training Time: {elapsed_time:.2f}s\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projet_7_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
